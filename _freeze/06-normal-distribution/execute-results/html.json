{
  "hash": "085237ad366d4b6974e59051c6bbfce4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"The Normal Distribution\"\n---\n\n# The Normal Distribution {#sec-normal-distribution}\n\n\n\n## Why the Normal Distribution Matters\n\nThe **Normal distribution** (also called the Gaussian distribution) is fundamental to statistics.\n\nMany statistical methods assume data follow a Normal distribution. Understanding it is essential for interpreting medical research.\n\n## Characteristics of the Normal Distribution\n\nThe Normal distribution has a distinctive **bell shape**:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- seq(-4, 4, 0.01)\ny <- dnorm(x)\n\nggplot(tibble(x, y), aes(x, y)) +\n  geom_area(fill = \"#3498db\", alpha = 0.4) +\n  geom_line(colour = \"#2c3e50\", linewidth = 1) +\n  geom_vline(xintercept = 0, colour = \"#e74c3c\", linewidth = 1, linetype = \"dashed\") +\n  annotate(\"text\", x = 0.15, y = 0.35, label = \"Mean (μ)\", hjust = 0, colour = \"#e74c3c\", size = 4) +\n  labs(x = \"Value\", y = \"Probability density\") +\n  theme_minimal() +\n  theme(axis.text.y = element_blank())\n```\n\n::: {.cell-output-display}\n![The Normal distribution: a symmetric, bell-shaped curve](06-normal-distribution_files/figure-html/fig-normal-curve-1.png){#fig-normal-curve width=768}\n:::\n:::\n\n\n**Key features:**\n\n- **Symmetric** around the mean\n- **Bell-shaped** curve\n- Mean = Median = Mode (all at the centre)\n- Completely described by just **two parameters**\n\n## The Two Parameters\n\nThe Normal distribution is fully defined by:\n\n| Parameter | Symbol | Meaning |\n|-----------|--------|---------|\n| Mean | μ (mu) | Centre of the distribution |\n| Standard deviation | σ (sigma) | Spread of the distribution |\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- seq(-6, 10, 0.01)\n\n# Different means\np1 <- ggplot() +\n  geom_line(aes(x = x, y = dnorm(x, mean = 0, sd = 1)), colour = \"#3498db\", linewidth = 1) +\n  geom_line(aes(x = x, y = dnorm(x, mean = 3, sd = 1)), colour = \"#e74c3c\", linewidth = 1) +\n  annotate(\"text\", x = 0, y = 0.35, label = \"μ = 0\", colour = \"#3498db\", size = 4) +\n  annotate(\"text\", x = 3, y = 0.35, label = \"μ = 3\", colour = \"#e74c3c\", size = 4) +\n  labs(x = \"Value\", y = \"Density\", title = \"Different means (same SD)\") +\n  theme_minimal()\n\n# Different SDs\np2 <- ggplot() +\n  geom_line(aes(x = x, y = dnorm(x, mean = 2, sd = 0.5)), colour = \"#3498db\", linewidth = 1) +\n  geom_line(aes(x = x, y = dnorm(x, mean = 2, sd = 1)), colour = \"#e74c3c\", linewidth = 1) +\n  geom_line(aes(x = x, y = dnorm(x, mean = 2, sd = 2)), colour = \"#27ae60\", linewidth = 1) +\n  annotate(\"text\", x = 2, y = 0.75, label = \"σ = 0.5\", colour = \"#3498db\", size = 3.5) +\n  annotate(\"text\", x = 2, y = 0.35, label = \"σ = 1\", colour = \"#e74c3c\", size = 3.5) +\n  annotate(\"text\", x = 2, y = 0.18, label = \"σ = 2\", colour = \"#27ae60\", size = 3.5) +\n  labs(x = \"Value\", y = \"Density\", title = \"Different SDs (same mean)\") +\n  theme_minimal()\n\np1 + p2\n```\n\n::: {.cell-output-display}\n![Normal distributions with different means and standard deviations](06-normal-distribution_files/figure-html/fig-normal-params-1.png){#fig-normal-params width=960}\n:::\n:::\n\n\n## The 95% Rule\n\n::: {.callout-important}\n## Key Property\nIn a Normal distribution, approximately **95% of values** lie within **1.96 standard deviations** of the mean.\n:::\n\nThis means 95% of the population falls between:\n\n$$\\mu - 1.96\\sigma \\quad \\text{and} \\quad \\mu + 1.96\\sigma$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- seq(-4, 4, 0.01)\ny <- dnorm(x)\n\nshade_data <- tibble(x, y) %>%\n  filter(x >= -1.96 & x <= 1.96)\n\nggplot() +\n  geom_area(data = tibble(x, y), aes(x, y), fill = \"grey80\", alpha = 0.5) +\n  geom_area(data = shade_data, aes(x, y), fill = \"#3498db\", alpha = 0.6) +\n  geom_line(data = tibble(x, y), aes(x, y), colour = \"#2c3e50\", linewidth = 1) +\n  geom_vline(xintercept = c(-1.96, 1.96), colour = \"#e74c3c\", linetype = \"dashed\", linewidth = 0.8) +\n  annotate(\"text\", x = 0, y = 0.15, label = \"95%\", size = 6, colour = \"#2c3e50\", fontface = \"bold\") +\n  annotate(\"text\", x = -2.5, y = 0.05, label = \"2.5%\", size = 4, colour = \"#7f8c8d\") +\n  annotate(\"text\", x = 2.5, y = 0.05, label = \"2.5%\", size = 4, colour = \"#7f8c8d\") +\n  annotate(\"text\", x = -1.96, y = -0.03, label = \"μ - 1.96σ\", size = 3.5, colour = \"#e74c3c\") +\n  annotate(\"text\", x = 1.96, y = -0.03, label = \"μ + 1.96σ\", size = 3.5, colour = \"#e74c3c\") +\n  labs(x = \"Value\", y = \"Probability density\") +\n  theme_minimal() +\n  theme(axis.text.y = element_blank())\n```\n\n::: {.cell-output-display}\n![95% of values in a Normal distribution lie within 1.96 standard deviations of the mean](06-normal-distribution_files/figure-html/fig-95-rule-1.png){#fig-95-rule width=768}\n:::\n:::\n\n\n### Reference Range\n\nThis property gives us the **reference range** – the range containing 95% of the population.\n\n**Example: Height of women**\n\nIf women's height is Normally distributed with μ = 1.61 m and σ = 0.07 m:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmu <- 1.61\nsigma <- 0.07\n\nlower <- mu - 1.96 * sigma\nupper <- mu + 1.96 * sigma\n\ncat(\"Reference range: \", round(lower, 2), \"m to\", round(upper, 2), \"m\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReference range:  1.47 m to 1.75 m\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"95% of women have heights in this range\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n95% of women have heights in this range\n```\n\n\n:::\n:::\n\n\n## Sample Estimates\n\nIn practice, we don't know μ and σ. We estimate them from sample data:\n\n| Population Parameter | Sample Estimate |\n|---------------------|-----------------|\n| μ (population mean) | x̄ (sample mean) |\n| σ (population SD) | SD (sample SD) |\n\nFor samples from a Normal distribution, approximately 95% of values fall between:\n\n$$\\bar{x} - 1.96 \\times SD \\quad \\text{and} \\quad \\bar{x} + 1.96 \\times SD$$\n\n## The Standard Error\n\nWhen we calculate a sample mean, how precise is it?\n\n### Sampling Variability\n\nIf we took another sample, the mean would likely be different. This variation is called **sampling variability**.\n\n### Standard Error (SE)\n\nThe **standard error** measures the precision of the sample mean:\n\n$$SE = \\frac{SD}{\\sqrt{n}}$$\n\n**Key insight:** As sample size (n) increases, the standard error decreases – larger samples give more precise estimates.\n\n\n::: {#tbl-se-example .cell tbl-cap='Standard error decreases with sample size'}\n\n```{.r .cell-code}\nse_table <- tibble(\n  `Sample Size (n)` = c(10, 50, 100, 500, 5000),\n  `SD` = rep(0.07, 5)\n) %>%\n  mutate(\n    `√n` = round(sqrt(`Sample Size (n)`), 2),\n    `SE = SD/√n` = round(SD / sqrt(`Sample Size (n)`), 4)\n  )\n\nkable(se_table, align = \"c\")\n```\n\n::: {.cell-output-display}\n\n\n| Sample Size (n) |  SD  |  √n   | SE = SD/√n |\n|:---------------:|:----:|:-----:|:----------:|\n|       10        | 0.07 | 3.16  |   0.0221   |\n|       50        | 0.07 | 7.07  |   0.0099   |\n|       100       | 0.07 | 10.00 |   0.0070   |\n|       500       | 0.07 | 22.36 |   0.0031   |\n|      5000       | 0.07 | 70.71 |   0.0010   |\n\n\n:::\n:::\n\n\n## Confidence Intervals\n\nA **confidence interval** gives a range of plausible values for the population mean.\n\n### 95% Confidence Interval for the Mean\n\n$$\\bar{x} - 1.96 \\times SE \\quad \\text{to} \\quad \\bar{x} + 1.96 \\times SE$$\n\n::: {.callout-note}\n## Interpretation\nA 95% confidence interval means: if we repeated the study many times, 95% of the calculated intervals would contain the true population mean.\n:::\n\n**Example: Women's height (n = 5,628)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 5628\nmean_height <- 1.61\nsd_height <- 0.07\nse <- sd_height / sqrt(n)\n\nci_lower <- mean_height - 1.96 * se\nci_upper <- mean_height + 1.96 * se\n\ncat(\"Sample mean:\", mean_height, \"m\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSample mean: 1.61 m\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Standard error:\", round(se, 4), \"m\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStandard error: 9e-04 m\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"95% CI:\", round(ci_lower, 3), \"to\", round(ci_upper, 3), \"m\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n95% CI: 1.608 to 1.612 m\n```\n\n\n:::\n:::\n\n\nWith a large sample, our estimate is very precise (narrow CI).\n\n## Skewed Distributions\n\nNot all data are Normally distributed. Skewed data are common in medicine.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\nvolumes <- rexp(88, 0.15)\n\np1 <- ggplot(tibble(x = volumes), aes(x = x)) +\n  geom_histogram(bins = 15, fill = \"#3498db\", colour = \"white\", alpha = 0.7) +\n  labs(x = \"Lesion Volume (cm³)\", y = \"Frequency\", title = \"Original data (skewed)\") +\n  theme_minimal()\n\np2 <- ggplot(tibble(x = log(volumes)), aes(x = x)) +\n  geom_histogram(bins = 15, fill = \"#27ae60\", colour = \"white\", alpha = 0.7) +\n  labs(x = \"Log(Volume)\", y = \"Frequency\", title = \"Log-transformed (more symmetric)\") +\n  theme_minimal()\n\np1 + p2\n```\n\n::: {.cell-output-display}\n![Tumour volume (left) showing positive skew, and log-transformed data (right) approaching Normality](06-normal-distribution_files/figure-html/fig-skewed-transform-1.png){#fig-skewed-transform width=960}\n:::\n:::\n\n\n### Dealing with Non-Normal Data\n\n| Approach | When to Use |\n|----------|-------------|\n| Log transformation | Positively skewed data |\n| Square transformation | Negatively skewed data |\n| Non-parametric methods | When transformation doesn't help |\n\n## The Central Limit Theorem\n\n::: {.callout-tip}\n## A Remarkable Result\nThe **Central Limit Theorem** states that the distribution of sample means will be approximately Normal, **regardless of the original distribution**, as long as the sample size is large enough.\n:::\n\nThis is why many statistical methods work even when individual values are not Normally distributed – we often work with means, not individual values.\n\n## Summary\n\n- The **Normal distribution** is symmetric and bell-shaped\n- It is completely described by **mean (μ)** and **standard deviation (σ)**\n- **95% of values** lie within 1.96 SDs of the mean\n- The **standard error** measures precision of the sample mean\n- **Confidence intervals** give plausible ranges for population parameters\n- Skewed data can often be **transformed** to approximate Normality\n- The **Central Limit Theorem** means sample means tend to be Normally distributed\n",
    "supporting": [
      "06-normal-distribution_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}