{
  "hash": "3e62a69f8d2dfa7f4cf1fdd8c033ce93",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Statistical Inference\"\n---\n\n# Concepts in Statistical Inference {#sec-statistical-inference}\n\n\n\n## The Logic of Statistical Inference\n\nConsider this historical example:\n\n> Until the end of the 17th century, Europeans assumed all swans were white. This hypothesis was rejected when Willem de Vlamingh spotted a black swan in Australia in 1697.\n\n**The null hypothesis** (\"All swans are white\") was assumed true until evidence proved otherwise.\n\nStatistical inference follows the same logic:\n\n1. Start with a hypothesis\n2. Assume it is true\n3. Collect data\n4. Seek evidence to reject or fail to reject it\n\n## Hypotheses\n\n### The Null Hypothesis (H₀)\n\nThe **null hypothesis** is a statement of \"no difference\" or \"no effect.\"\n\nWe assume H₀ is true unless the evidence strongly suggests otherwise.\n\n**Example:** In a clinical trial comparing a new drug to standard treatment:\n\n> **H₀:** There is no difference in blood pressure between the new drug and standard treatment\n\n### The Alternative Hypothesis (H₁)\n\nThe **alternative hypothesis** is what we suspect might be true – the opposite of H₀.\n\n> **H₁:** There is a difference in blood pressure between the drugs\n\n::: {.callout-note}\n## Why Start with \"No Effect\"?\nWe begin by assuming no effect because it's easier to disprove something than to prove it. One black swan disproves \"all swans are white,\" but millions of white swans can never prove it.\n:::\n\n## The P-value\n\nAfter collecting data, we calculate a **test statistic** and convert it to a **P-value**.\n\n### What is a P-value?\n\n::: {.callout-important}\n## Definition\nThe **P-value** is the probability of observing results as extreme as (or more extreme than) what we found, **assuming the null hypothesis is true**.\n:::\n\n### Interpreting P-values\n\n| P-value | Interpretation |\n|---------|----------------|\n| Small (e.g., P < 0.05) | Results are unlikely if H₀ were true → Evidence against H₀ |\n| Large (e.g., P > 0.05) | Results could easily occur if H₀ were true → Insufficient evidence against H₀ |\n\n### The 0.05 Threshold\n\nBy convention, P < 0.05 is considered **statistically significant**.\n\n- **P < 0.05**: Reject H₀ in favour of H₁ – results are \"statistically significant\"\n- **P ≥ 0.05**: Cannot reject H₀ – results are \"not statistically significant\"\n\n::: {.callout-warning}\n## Important!\nP > 0.05 does **not** mean H₀ is true. It means we don't have enough evidence to reject it.\n:::\n\n## One-tailed vs Two-tailed Tests\n\n### Two-tailed Test\n\nThe alternative hypothesis does not specify a direction:\n\n> **H₁:** The drugs have different effects (could be better OR worse)\n\nThis is the standard approach.\n\n### One-tailed Test\n\nThe alternative hypothesis specifies a direction:\n\n> **H₁:** The new drug is better than the standard drug\n\nOne-tailed tests are generally **discouraged** because we rarely know beforehand which direction the effect will be.\n\n## Type I and Type II Errors\n\nWhen making decisions, we can make two types of mistakes:\n\n\n::: {#tbl-errors .cell tbl-cap='Type I and Type II errors in hypothesis testing'}\n\n```{.r .cell-code}\nerror_table <- tibble(\n  ` ` = c(\"**Reject H₀**\", \"**Do not reject H₀**\"),\n  `H₀ is actually TRUE` = c(\"Type I error\\n(false positive)\", \"✓ Correct decision\"),\n  `H₀ is actually FALSE` = c(\"✓ Correct decision\", \"Type II error\\n(false negative)\")\n)\n\nkable(error_table, align = \"c\")\n```\n\n::: {.cell-output-display}\n\n\n|                      |     H₀ is actually TRUE      |     H₀ is actually FALSE      |\n|:--------------------:|:----------------------------:|:-----------------------------:|\n|    **Reject H₀**     | Type I error\n(false positive) |      ✓ Correct decision       |\n| **Do not reject H₀** |      ✓ Correct decision      | Type II error\n(false negative) |\n\n\n:::\n:::\n\n\n### Type I Error (False Positive)\n\n- Concluding there **is** an effect when there **isn't** one\n- Probability = **α (alpha)** = significance level (usually 0.05)\n\n**Example:** Approving an ineffective drug\n\n### Type II Error (False Negative)\n\n- Concluding there **is no** effect when there **is** one\n- Probability = **β (beta)**\n\n**Example:** Dismissing an effective treatment\n\n### Power\n\n**Power** = 1 - β = Probability of correctly detecting a real effect\n\n> Power is the chance of rejecting H₀ when it is actually false (i.e., detecting a true effect)\n\n## Confidence Intervals vs P-values\n\nBoth provide information about statistical significance, but confidence intervals offer more:\n\n| P-value | Confidence Interval |\n|---------|---------------------|\n| Tells us if result is significant | Tells us if result is significant |\n| Doesn't show effect size | Shows plausible range of effect sizes |\n| Binary (significant or not) | Continuous (narrow = precise, wide = imprecise) |\n\n### Using Confidence Intervals\n\nIf the 95% CI for a difference excludes zero:\n\n- The difference is statistically significant (P < 0.05)\n- We have evidence of a real effect\n\n**Example:** New drug reduces blood pressure by 8 mmHg (95% CI: 3 to 13 mmHg)\n\n- The CI excludes 0 → Statistically significant\n- We can be confident the true effect is between 3 and 13 mmHg\n\n## Choosing the Right Test\n\n### Tests for Numerical Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create flow chart data\nlibrary(ggplot2)\n\nboxes <- tibble(\n  label = c(\"Normally\\nDistributed?\", \n            \"1 Sample\", \"2 Samples\",\n            \"Student's\\nt-test\", \"Independent\", \"Paired\",\n            \"Two-sample\\nt-test\", \"Paired\\nt-test\",\n            \"1 Sample\", \"2 Samples\",\n            \"Wilcoxon\\nsigned-rank\", \"Independent\", \"Paired\",\n            \"Mann-Whitney\\nU test\", \"Wilcoxon\\nsigned-rank\"),\n  x = c(5, 2.5, 7.5, 2.5, 6.5, 8.5, 6.5, 8.5,\n        2.5, 7.5, 2.5, 6.5, 8.5, 6.5, 8.5),\n  y = c(6, 4.5, 4.5, 3, 3, 3, 1.5, 1.5,\n        4.5, 4.5, 3, 3, 3, 1.5, 1.5) - 3,\n  fill = c(\"#3498db\", \"#27ae60\", \"#27ae60\", \"#e74c3c\", \"#27ae60\", \"#27ae60\", \"#e74c3c\", \"#e74c3c\",\n           \"#27ae60\", \"#27ae60\", \"#e74c3c\", \"#27ae60\", \"#27ae60\", \"#e74c3c\", \"#e74c3c\")\n)\n\n# Just show the key decisions\nkey_boxes <- tibble(\n  label = c(\"Is data\\nNormally distributed?\", \n            \"YES:\\nParametric tests\",\n            \"NO:\\nNon-parametric tests\"),\n  x = c(5, 2.5, 7.5),\n  y = c(3, 1.5, 1.5),\n  fill = c(\"#3498db\", \"#27ae60\", \"#e74c3c\")\n)\n\nggplot(key_boxes, aes(x = x, y = y)) +\n  geom_tile(aes(fill = fill), width = 3, height = 1.2, colour = \"white\", linewidth = 2) +\n  geom_text(aes(label = label), colour = \"white\", size = 4, fontface = \"bold\") +\n  annotate(\"segment\", x = 3.8, xend = 3.2, y = 2.35, yend = 2.1, \n           arrow = arrow(length = unit(0.2, \"cm\")), colour = \"#2c3e50\") +\n  annotate(\"segment\", x = 6.2, xend = 6.8, y = 2.35, yend = 2.1,\n           arrow = arrow(length = unit(0.2, \"cm\")), colour = \"#2c3e50\") +\n  scale_fill_identity() +\n  theme_void() +\n  coord_cartesian(xlim = c(0, 10), ylim = c(0.5, 4))\n```\n\n::: {.cell-output-display}\n![Decision tree for choosing tests for numerical data](07-statistical-inference_files/figure-html/fig-numerical-tests-1.png){#fig-numerical-tests width=960}\n:::\n:::\n\n\n#### Parametric Tests (Normal data)\n\n| Situation | Test |\n|-----------|------|\n| One sample vs known value | One-sample t-test |\n| Two independent groups | Two-sample t-test |\n| Two paired measurements | Paired t-test |\n\n#### Non-parametric Tests (Non-Normal data)\n\n| Situation | Test |\n|-----------|------|\n| One sample vs known value | Wilcoxon signed-rank test |\n| Two independent groups | Mann-Whitney U test (Wilcoxon rank-sum) |\n| Two paired measurements | Wilcoxon signed-rank test |\n\n### Tests for Categorical Data\n\n| Situation | Test |\n|-----------|------|\n| Unpaired, large samples | Pearson chi-squared (χ²) test |\n| Unpaired, small samples (expected counts < 5) | Fisher's exact test |\n| Paired categorical data | McNemar's test |\n\n## Sample Size and Power\n\n### Why Sample Size Matters\n\nA study needs enough participants to have a reasonable chance of detecting a real effect.\n\n### Factors Affecting Power\n\n| Factor | Effect on Power |\n|--------|-----------------|\n| ↑ Sample size | ↑ Power |\n| ↑ Variability (SD) | ↓ Power |\n| ↑ Effect size sought | ↑ Power |\n| ↑ Significance level (α) | ↑ Power |\n\n### Underpowered Studies\n\nAn **underpowered** study (too few participants) may fail to detect a real effect:\n\n- Important findings may be missed\n- Negative results are inconclusive\n- Can be considered unethical\n\n### Overpowered Studies\n\nAn **overpowered** study (more participants than needed):\n\n- Wastes resources\n- May detect trivially small effects that aren't clinically meaningful\n- Exposes unnecessary participants to research procedures\n\n## Clinical vs Statistical Significance\n\n::: {.callout-warning}\n## A Critical Distinction\n**Statistical significance** (P < 0.05) does not mean **clinical significance**.\n\nA statistically significant result may be too small to matter clinically.\n:::\n\n**Example:** A new drug lowers blood pressure by 2 mmHg (P = 0.001)\n\n- Statistically significant? **Yes** (P < 0.05)\n- Clinically significant? **Probably not** (2 mmHg is unlikely to reduce cardiovascular events)\n\nAlways consider:\n\n1. Is the result statistically significant?\n2. Is the effect size clinically meaningful?\n3. Is the confidence interval narrow enough to be useful?\n\n## Summary\n\n- The **null hypothesis (H₀)** assumes no effect; we seek evidence to reject it\n- A **P-value** is the probability of the observed results if H₀ were true\n- **P < 0.05** is conventionally \"statistically significant\"\n- **Type I error**: concluding an effect exists when it doesn't\n- **Type II error**: missing a real effect\n- **Power**: probability of detecting a true effect\n- **Confidence intervals** provide more information than P-values alone\n- Choose tests based on data type and distribution\n- Always consider **clinical significance**, not just statistical significance\n",
    "supporting": [
      "07-statistical-inference_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}